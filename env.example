# Proxy Server Configuration
PROXY_HOST=0.0.0.0
PROXY_PORT=3000

# OpenRouter API Configuration
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Logging Configuration
LOG_LEVEL=INFO

# LangFuse Configuration (Optional)
# Set to 'true' to enable LangFuse logging (requires locally hosted LangFuse)
LANGFUSE_ENABLED=false

# LangFuse API Key (required if LANGFUSE_ENABLED=true)
# Get from your LangFuse instance
LANGFUSE_API_KEY=your-langfuse-api-key-here

# LangFuse Secret Key (required if LANGFUSE_ENABLED=true)
# Get from your LangFuse instance
LANGFUSE_SECRET_KEY=your-langfuse-secret-key-here

# LangFuse Host (optional, defaults to 'http://localhost:3000')
# Change to your LangFuse server address if different
LANGFUSE_HOST=http://localhost:3000

# Model Overrides (Optional)
# Redirect hardcoded model names to different providers/models
# Format: MODEL_OVERRIDE_<UPPERCASE_MODEL_NAME_WITH_UNDERSCORES>=<TARGET_MODEL>
#
# Example: If the app is hardcoded to use claude-haiku-4-5-20251001 but you want to use Moonshot:
# MODEL_OVERRIDE_CLAUDE_HAIKU_4_5_20251001=moonshotai/kimi-k2-thinking
#
# Example: Redirect Claude Sonnet 4 to OpenAI GPT-4:
# MODEL_OVERRIDE_CLAUDE_SONNET_4_20250514=openai/gpt-4-turbo-preview
#
# Example: Redirect Claude Opus 4 to Meta Llama:
# MODEL_OVERRIDE_CLAUDE_OPUS_4_20250514=meta-llama/llama-3.1-70b-instruct
